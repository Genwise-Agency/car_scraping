name: BMW Car Scraping Pipeline

on:
    schedule:
        # Runs at 9:00 UTC (10:00 CET / 11:00 CEST) and 14:00 UTC (15:00 CET / 16:00 CEST)
        - cron: "0 9,14 * * *"
    workflow_dispatch: # Allow manual triggering from GitHub UI

jobs:
    scrape:
        runs-on: ubuntu-latest

        steps:
            - name: Checkout repository
              uses: actions/checkout@v4

            - name: Set up Python 3.12
              uses: actions/setup-python@v4
              with:
                  python-version: "3.12"

            - name: Install system dependencies for Playwright
              run: |
                  sudo apt-get update
                  sudo apt-get install -y --no-install-recommends \
                    libnss3 libatk-bridge2.0-0 libdrm2 libxkbcommon0 libxcomposite1 libxdamage1 \
                    libxrandr2 libgbm1 libxss1 libappindicator3-1 libasound2 libx11-xcb1 libxcb-dri3-0 libxext6 \
                    libxfixes3 libxi6 libxrender1 libxtst6 libgtk-3-0 libgdk-pixbuf2.0-0 \
                    libpango-1.0-0 libharfbuzz0b libpangoft2-1.0-0 libfontconfig1 libcairo2 \
                    libglib2.0-0 libcairo-gobject2 libatk1.0-0 libcups2 libdbus-1-3 libpangocairo-1.0-0 libnspr4

            - name: Install Python dependencies
              run: |
                  python -m pip install --upgrade pip
                  pip install -r requirements.txt

            - name: Install Playwright browsers
              run: |
                  python -m playwright install chromium --with-deps

            - name: Run BMW scraping pipeline
              env:
                  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
                  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
                  BMW_URL: ${{ secrets.BMW_URL }}
                  SYNC_DB: "true"
                  TEST_LIMIT: "0"
              run: |
                  cd /home/runner/work/car_scraping/car_scraping
                  python -c "
                  import sys
                  sys.path.insert(0, 'src')
                  from bmw.main import main
                  main(
                      url='${{ secrets.BMW_URL }}',
                      test_limit=None,
                      sync_db=True
                  )
                  "

            - name: Upload results as artifacts
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: scraping-results
                  path: results/bmw/
                  retention-days: 30

            - name: Notify on failure
              if: failure()
              run: |
                  echo "‚ùå BMW scraping pipeline failed"
                  echo "Check logs: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
